# Software Engineering

## #12 Software Evaluation ‚úÖ / "Closing DevOps" ‚öôÔ∏èüîç

WSEG / FS24<br />

[Source](https://github.com/digital-sustainability/module-wseg/tree/24/fs/docs/slides/content/12) licensed under [CC-BY-4.0](https://github.com/digital-sustainability/module-wseg/blob/24/fs/LICENSE)

--

1. R√ºckblick
2. Software Evaluation
3. DevOps: Op & Mon
4. Ausblick / Lernstick Pr√ºfungsumgebung
5. Ausf√ºllen Evaluation
6. Coaching Teil 3

--

### [Cross-Origin_Resource_Sharing](https://de.wikipedia.org/wiki/Cross-Origin_Resource_Sharing)?

https://docs.strapi.io/dev-docs/configurations/middlewares#cors

```
  {
    name: 'strapi::cors',
    config: {
      enabled: true,
      headers: '*',
      origin: ['http://localhost:1337', 'http://localhost:4200']
    }
  },
```

---

### Begriff: "Software Evaluation"

> (Fast) fertige Produkte oder Anleitungen auf Usability optimieren

Ziele:

- Bessere Wettbewerbsf√§higkeit
- Steigerung der Wertsch√∂pfung beim Kunden
- Senkung anfallender Kosten beim Hersteller
  - Beispiel Transline (100k f√ºr Dokumentation)

Note:
√úbersetzungssoftware: 30% Senkung der Hotlinekosten um 2 Mio
https://www.transline.de/wissenswertes/kostensenkung-durch-bessere-dokumentation/

--

### Versus: Nutzungsforschung / Gestaltung

- Persona / Use Cases / Marktanalyse
- Card Sorting / Wording
- Prototyping<br />&nbsp;

#### User-Centered Design ab Beginn

F√ºr Usability-Probleme gilt auch die "Rule of ten"!

--

### Qualitative Methoden zur Evaluation

- Expert\*innen
- Nutzer\*innen

--

### Experts

- Heuristic Evaluation
  - Erfahrungsbasiert (z.B. [Nielsen](https://www.nngroup.com/articles/ten-usability-heuristics/))
  - Kriterienkataloge (ISO 9241-110)
- [Cognitive Walkthrough](https://de.wikipedia.org/wiki/Cognitive_Walkthrough)
  - Schwachstellen in der Interaktion mit UI entdecken

---

#### Users

> Mit 5 Testpersonen (pro Persona) findet man 80% der Erkenntnisse √ºber Usability-Probleme.

- Feldtest
- Usability-Test: Labortest / Remote
  - mit Eyetracking
- Usability-Walkthrough
- Quantitativ: A/B-Test, [SUS](https://de.wikipedia.org/wiki/System_Usability_Scale) etc.
- Benutzertagebuch

--

### Methode: Feldtest

- heimliches beobachten
- anschliessend befragen

#### Vorteile

- Keine Simulation, keine Beeinflussung
- Nutzende sind unbelastet / unvoreingenommen
- neue Ideen duch unerwartete Situationen

#### Nachteile

- Fortgeschrittener Prototyp notwendig
- Zufallsverteilung

--

### Methode: Labortest

- vorgegebene Aufgaben l√∂sen
- Beobachter in separatem Raum
- ggf. auch remote durchf√ºhrbar

#### Vorteile

- wenig Beeinflussung/Ablenkung
- geringe Versuchsabweichung

#### Nachteile

- zeit-/kostenintensiv
- Szenario f√ºhrt Testperson

--

### Methode: Usability-Walkthrough

- Testperson nutzt Produkt (Website, App...), denkt laut und kommentiert.
- Moderator\*in stellt R√ºckfragen, wo n√∂tig.
- Abschliessendes Interview
- auch remote durchf√ºhrbar

--

#### Vorteile

- Individuelle Anpassung an Testperson (Rhythmus, Aufgaben)
- Direkter Einfluss auf gewisse Probleme m√∂glich, keine ¬´Sackgassen¬ª
- Intensive Diskussion m√∂glich

#### Nachteile

- reale Nutzungssituation kaum simuliert
- Hohe Moderationskompetenz notwendig

--

## Fragen?

<!-- .slide: data-background="#fff5c1" -->
